{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung einfaches Neuronales Netz mit Python:\n",
    "\n",
    "<br/>\n",
    "\n",
    "-  Ziel ist die Erstellung eines einfachen Neuronalen Netzes bestehend aus 3 Schichten:\n",
    "-  Einer Input-Schicht, eine Hidden-Schicht und eine Output-Schicht mit je 3 Neuronen (Knoten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grundgerüst Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuronalesNetz:\n",
    "    \n",
    "    # Initialisierung Netzarchitektur\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.innodes = inputnodes\n",
    "        self.hidnodes = hiddennodes\n",
    "        self.outnodes = outputnodes\n",
    "        self.lr = learningrate       \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Gewichte anhand Trainingsbeispielen trainieren\n",
    "    def train():        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # für gegebenen Input, einen Ouput vom Neuronalen Netz abfragen\n",
    "    def query():     \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung einfaches Netz mit einer Hidden Layer und 3 Knoten je Schicht\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "# Learnrate moderiert Stärke der Gewichtsanpassung\n",
    "learning_rate = 0.3\n",
    "\n",
    "nn = neuronalesNetz(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gewichte initialisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Verknüpfungsgewichte bestimmen Signalanteile, die das Netz vorwärts leitet. <br>\n",
    "-   Verknüfungsgewichte bestimmen Fehleranteile, die das Netz rückwärts leitet (Backpropagation)\n",
    "<br><br>\n",
    "-   Gewichtsmatrix WIH verbindet Input- mit Hiddenschicht und hat Shape: (hidden_nodes X input_nodes)\n",
    "-   Gewichtsmatrix WHO verbindet Hidden- mit Outputschicht und hat Shape: (output_nodes X hidden_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einfache Variante mit Array-Erzeugung über numpy.random.rand(rows, columns)\n",
    "import numpy as np\n",
    "\n",
    "wih = np.random.rand(hidden_nodes, input_nodes)-0.5 # -0.5 um auch negative Gewichte zu erzeugen\n",
    "who = np.random.rand(output_nodes, hidden_nodes)-0.5\n",
    "\n",
    "# Differenziertere Variante mit Array-Erzeugung über numpy.random.normal(rows, columns)\n",
    "# numpy.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "\n",
    "wih = np.random.normal(loc=0.0, scale=pow(hidden_nodes, -0.5), size=(hidden_nodes, input_nodes))\n",
    "who = np.random.normal(loc=0.0, scale=pow(output_nodes,-0.5), size=(output_nodes, hidden_nodes))\n",
    "\n",
    "# Standardbweichung der Normalverteilung gemäß Faustregel als Kehrwert der Qudaratwurzel\n",
    "# aus Anzahl Verknüpfungen ZU einem Knoten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class neuronalesNetz:\n",
    "    \n",
    "    # Initialisierung Netzarchitektur\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.innodes = inputnodes\n",
    "        self.hidnodes = hiddennodes\n",
    "        self.outnodes = outputnodes\n",
    "        self.lr = learningrate       \n",
    "        \n",
    "        wih = np.random.normal(loc=0.0, scale=pow(self.hidnodes, -0.5), size=(self.hidnodes, self.innodes))\n",
    "        who = np.random.normal(loc=0.0, scale=pow(self.outnodes, -0.5), size=(self.outnodes, self.hidnodes))      \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Gewichte anhand Trainingsbeispielen trainieren\n",
    "    def train():       \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # für gegebenen Input, einen Ouput vom Neuronalen Netz abfragen\n",
    "    def query():      \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query-Funktion: Eingaben durch das Netz leiten\n",
    "<br/>\n",
    "\n",
    "Input-Signal → Summation Eingänge → Sigmoid-Aktivierungsfunktion → Output-Signal\n",
    "\n",
    "-  1. Verbindung Input-Schicht mit Hidden-Schicht: \n",
    "-  2. Verbindung Hidden-Schicht mit Output-Schicht: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special # Sigmoid-Aktivierungsfunktion liegt als \"expit()\" in dieser Bibliothek\n",
    "\n",
    "activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "def query(self, input_list): # Eingabe ist eine liste  \n",
    "    \n",
    "    inputs = np.array(input_list, ndmin = 2).T # ndmin: minimum number of dimensions the resulting array should have\n",
    "    \n",
    "    # Verarbeitung Eingabe bis Ausgabe Hidden-Schicht\n",
    "    hidden_in = np.dot(wih, inputs) # Punktprodukut/Matrixmultiplikation/Skalarprodukt\n",
    "    hidden_out = activation_function(hidden_in) # Sigmoid-Aktivierungsfunktion auf Signal anwenden\n",
    "    \n",
    "    # Verarbeitung Ausgabe Hidden-Schicht bis finale Ausgabe\n",
    "    output_in = np.dot(who, hidden_out) \n",
    "    output_out = activation_function(output_in) \n",
    "    return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special # Sigmoid-Aktivierungsfunktion liegt als \"expit()\" in dieser Bibliothek\n",
    "\n",
    "class neuronalesNetz:\n",
    "    \n",
    "    # Initialisierung Netzarchitektur\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.innodes = inputnodes\n",
    "        self.hidnodes = hiddennodes\n",
    "        self.outnodes = outputnodes\n",
    "        self.lr = learningrate       \n",
    "        \n",
    "        self.wih = np.random.normal(loc=0.0, scale=pow(self.hidnodes, -0.5), size=(self.hidnodes, self.innodes))\n",
    "        self.who = np.random.normal(loc=0.0, scale=pow(self.outnodes, -0.5), size=(self.outnodes, self.hidnodes)) \n",
    "        \n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # Gewichte anhand Trainingsbeispielen trainieren\n",
    "    def train():     \n",
    "        pass\n",
    " \n",
    "\n",
    "    # für gegebenen Input, einen Ouput vom Neuronalen Netz abfragen\n",
    "    def query(self, input_list):   \n",
    "        \n",
    "        inputs = np.array(input_list, ndmin = 2).T # ndmin: minimum number of dimensions the resulting array should have\n",
    "        \n",
    "        # Verarbeitung Eingabe bis Ausgabe Hidden-Schicht\n",
    "        hidden_in = np.dot(wih, inputs) # Punktprodukt/Matrixmultiplikation/Skalarprodukt\n",
    "        hidden_out = activation_function(hidden_in) # Sigmoid-Aktivierungsfunktion auf Signal anwenden\n",
    "        \n",
    "        # Verarbeitung Ausgabe Hidden-Schicht bis finale Ausgabe\n",
    "        output_in = np.dot(who, hidden_out) \n",
    "        output_out = activation_function(output_in) \n",
    "        return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25220966],\n",
       "       [0.61656922],\n",
       "       [0.38253791]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test, ob alle Funktionen bis jetzt funktionieren\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "learning_rate = 0.3\n",
    "\n",
    "nn = neuronalesNetz(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "nn.query([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Funktion \n",
    "\n",
    "-  1. Ausgabe für Trainingsbeispiel von Netz berechnen lassen\n",
    "-  2. Fehler der Ausgabe berechnen, Fehlerrückrechnung für jede Schicht, Gewichtsktualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Gewichte anhand Trainingsbeispielen trainieren\n",
    "def train(self,input_list, target_list): \n",
    "    \n",
    "    inputs = np.array(input_list, ndmin = 2).T \n",
    "    targets = np.array(target_list, ndmin = 2).T\n",
    "    \n",
    "    # 1. Ausgabe für Trainingsbeispiel von Netz berechnen lassen\n",
    "    hidden_in = np.dot(self.wih, inputs) \n",
    "    hidden_out = self.activation_function(hidden_in) \n",
    "    output_in = np.dot(self.who, hidden_out) \n",
    "    output_out = self.activation_function(output_in)\n",
    "    \n",
    "    # 2. Fehler der Ausgabe berechnen + Fehlerrückrechnung\n",
    "    output_errors = targets - output_out\n",
    "    hidden_errors = np.dot(self.who.T, output_errors)\n",
    "    \n",
    "    # Gewichtsktualisierung für who und wih\n",
    "    self.who += self.lr * np.dot(outout_errors * output_out(1-output_out), np.transpose(hidden_out))\n",
    "    self.wih += self.lr * np.dot(hidden_errors * hidden_out(1-hidden_out), np.transpose(inputs))       \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finales einfaches Neuronales Netz mit 3 Schichten à 3 Knoten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special # Sigmoid-Aktivierungsfunktion liegt als \"expit()\" in dieser Bibliothek\n",
    "\n",
    "class neuronalesNetz:\n",
    "    \n",
    "    # Initialisierung Netzarchitektur\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.innodes = inputnodes\n",
    "        self.hidnodes = hiddennodes\n",
    "        self.outnodes = outputnodes\n",
    "        self.lr = learningrate       \n",
    "        \n",
    "        self.wih = np.random.normal(loc=0.0, scale=pow(self.hidnodes, -0.5), size=(self.hidnodes, self.innodes))\n",
    "        self.who = np.random.normal(loc=0.0, scale=pow(self.outnodes, -0.5), size=(self.outnodes, self.hidnodes)) \n",
    "        \n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # Gewichte anhand Trainingsbeispielen trainieren\n",
    "    def train(self,input_list, target_list): \n",
    "\n",
    "        inputs = np.array(input_list, ndmin = 2).T \n",
    "        targets = np.array(target_list, ndmin = 2).T\n",
    "\n",
    "        # 1. Ausgabe für Trainingsbeispiel von Netz berechnen lassen\n",
    "        hidden_in = np.dot(self.wih, inputs) \n",
    "        hidden_out = self.activation_function(hidden_in) \n",
    "        output_in = np.dot(self.who, hidden_out) \n",
    "        output_out = self.activation_function(output_in)\n",
    "\n",
    "        # 2. Fehler der Ausgabe berechnen + Fehlerrückrechnung\n",
    "        output_errors = targets - output_out\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "\n",
    "        # Gewichtsktualisierung für who und wih\n",
    "        self.who += self.lr * np.dot(outout_errors * output_out(1-output_out), np.transpose(hidden_out))\n",
    "        self.wih += self.lr * np.dot(hidden_errors * hidden_out(1-hidden_out), np.transpose(inputs))       \n",
    "        pass\n",
    " \n",
    "\n",
    "    # für gegebenen Input, einen Ouput vom Neuronalen Netz abfragen\n",
    "    def query(self, input_list):   \n",
    "        \n",
    "        inputs = np.array(input_list, ndmin = 2).T # ndmin: minimum number of dimensions the resulting array should have\n",
    "        \n",
    "        # Verarbeitung Eingabe bis Ausgabe Hidden-Schicht\n",
    "        hidden_in = np.dot(wih, inputs) # Punktprodukt/Matrixmultiplikation/Skalarprodukt\n",
    "        hidden_out = activation_function(hidden_in) # Sigmoid-Aktivierungsfunktion auf Signal anwenden\n",
    "        \n",
    "        # Verarbeitung Ausgabe Hidden-Schicht bis finale Ausgabe\n",
    "        output_in = np.dot(who, hidden_out) \n",
    "        output_out = activation_function(output_in) \n",
    "        return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
